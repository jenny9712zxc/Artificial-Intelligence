{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d72ef6",
   "metadata": {},
   "source": [
    "# PyTorch Homework\n",
    "## 作業說明\n",
    "這個作業希望以 PyTorch 的框架透過實作讓同學了解基本的讀取資料集、搭建模型以及訓練的過程。\n",
    "\n",
    "這次作業分成三大部份及若干小部份，有一些**被註解框起來的區域**以及 **?** 的部份需要完成。\n",
    "\n",
    "1. **資料準備 - 30%**\n",
    "    + Transformation\n",
    "    + Custom dataset definition - 10%\n",
    "    + Create datasets - 10%\n",
    "    + Create dataloaders - 10%\n",
    "\n",
    "\n",
    "2. **建立模型 - 35%**\n",
    "    + flatten function - 5%\n",
    "    + 使用 nn.Module 建立模型 - 10%\n",
    "    + 使用 nn.Sequential 建立模型 - 10%\n",
    "    + 自己設計模型 - 10%\n",
    "    \n",
    "\n",
    "3. **訓練模型 - 35%**\n",
    "    + Loss function & optimizer - 5%\n",
    "    + 訓練 - 20%\n",
    "        + 完成程式碼 - 10%\n",
    "        + 自行設計的模型測試集準確率(只看最後 5 個 epoch 中的 best accuracy) - 10%\n",
    "            + 達到 50% baseline - 5%\n",
    "            + Bonus: 準確率超過 baseline 越多拿越高 - 5% \n",
    "    + 儲存模型 - 5%\n",
    "    + 繪製 loss 及 accuracy 圖表 - 5%\n",
    "\n",
    "## 作業繳交\n",
    "1. 繳交期限：\n",
    "\n",
    "\n",
    "2. 繳交方式：\n",
    "    \n",
    "    只需繳交這份完成的 ipynb 檔至 moodle，每個 cell 的執行結果都要顯示出來(訓練過程、loss curves 等等)，會用這些結果評分，不需要上傳訓練好的模型。\n",
    "    \n",
    "    檔案命名格式：學號_姓名_hw2.ipynb (ex: F12345678_王大明_hw2.ipynb)\n",
    "    * **格式不對的話會扣 10 分！！！**\n",
    "    \n",
    "\n",
    "3. 有問題請寄信至助教信箱 ne6094041@gs.ncku.edu.tw 或於 TA hour 至資訊新館65601室找助教詢問。\n",
    "    + TA hour: 星期一和四 14:00 ~ 16:30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e84958",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchviz import make_dot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef8591",
   "metadata": {},
   "source": [
    "## Hyperparamters\n",
    "可以自行新增或調整需要的 hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# data\n",
    "DATA_PATH = 'stanford_dog'\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "MEAN, STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225) # mean and std for ImageNet\n",
    "\n",
    "# training\n",
    "LR = 1e-3\n",
    "EPOCHS = 40\n",
    "USE_CUDA = False # use cuda or not\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c1abd",
   "metadata": {},
   "source": [
    "## GPU Setting\n",
    "用 ```torch.cuda.is_available()``` 測試系統是否能使用 cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c987829",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if USE_CUDA and torch.cuda.is_available(): # 若想使用 cuda 且可以使用 cuda\n",
    "    device = 'cuda'\n",
    "print(f'Using {device} for training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7240b838",
   "metadata": {},
   "source": [
    "## 1. Preparing Dataset\n",
    "PyTorch 中處理資料的部份主要由兩種 API 組成:\n",
    "+ ```Dataset```: 定義如何讀取資料，並對資料做前處理(搭配 ```transforms```)\n",
    "+ ```DataLoader```: 負責將多個樣本打包成 mini-batch 、處理資料取樣、以 multi-threading 或 multi-processing 的方式讀取資料等等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab07be",
   "metadata": {},
   "source": [
    "### 1.1 Transformations\n",
    "Pytorch 的 ```transforms``` API 包含許多常用的方法，如縮放、剪裁、翻轉、旋轉、自定義 transform 等等，也包含不同影像格式之間與 tensor 的型態轉換。\n",
    "\n",
    "每個 transform 方法可以單獨地被套用在影像上，也可以使用 ```Compose()``` 將許多方法組合在一起，並且會自動地照組合順序套用在影像上\n",
    "\n",
    "這裡的 transformations 是常見且基本的組合，雖然這裡不需要填寫，但你可以在裡面增加一些 augmentation 幫助後面的模型訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=MEAN, std=STD)\n",
    "\n",
    "# a set of common trasnformation combination for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# transformations for testing do not need to do fancy tricks\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db351d80",
   "metadata": {},
   "source": [
    "### 1.2 定義 dataset\n",
    "自定義的資料集會繼承 ```Dataset```，並且 overwrite 以下 3 個 function:\n",
    "1. ```__init__```: 建立資料集中樣本的讀取路徑以及 label 清單\n",
    "2. ```__len__```: 回傳資料集大小，即樣本的數量\n",
    "3. ```__getitem__```: 實際讀取資料的 function ，根據給定的 index 讀取影像，並對影像進行 transformation ，最後回傳處理過的影像以及其 label 。\n",
    "\n",
    "在這裡，我們會將每張影像的讀取路徑儲存在 ```samples``` 裡，其對應的 label 儲存在 ```labels```中。\n",
    "\n",
    "請完成以下 ? 處以及被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogDataset(Dataset):\n",
    "    def __init__(self, samples, classes, cls_to_idx, transform=None):\n",
    "        \"\"\"\n",
    "        samples: 儲存每張影像的路徑以及 label 的清單\n",
    "        classes: 所有類別名稱的清單\n",
    "        cls_to_idx: 類別和對應 index 的 dict\n",
    "        transform: 要對影像執行的 transformation\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.classes = classes\n",
    "        self.cls_to_idx = cls_to_idx\n",
    "        self.targets = [s[1] for s in samples] # list of labels corresponding to samples\n",
    "        self.samples = [s[0] for s in samples] # list of sample paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(?)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        ###############################################################################\n",
    "        # TODO : get the image path and label of the given index from the lists       #\n",
    "        # Hints:                                                                      #\n",
    "        # path = ???                                                                  #\n",
    "        # label = ???                                                                 #\n",
    "        ###############################################################################\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ###############################################################################\n",
    "\n",
    "        # load the image using PIL.Image.open()\n",
    "        img = Image.open(path)\n",
    "        \n",
    "        ###############################################################################\n",
    "        # TODO : apply the transformation on the loaded image                         #\n",
    "        # Hints:                                                                      #\n",
    "        # img = ???                                                                   #\n",
    "        ###############################################################################\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TODO                                         #\n",
    "        ###############################################################################\n",
    "        \n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab09a8",
   "metadata": {},
   "source": [
    "### 1.3 Create datasets\n",
    "首先找出所有資料的路徑並儲存成清單\n",
    "\n",
    "這裡不用填寫，但需要執行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b521b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_files(folder):\n",
    "    \"\"\"\n",
    "    Getting the list of files and their labels.\n",
    "    \n",
    "    Returns:\n",
    "    classes: list of class names\n",
    "    cls_to_idx: dict that map class names to their interger labels\n",
    "    instances: dict that uses labels as keys and the corresponding tuples (samples, # of samples) as values\n",
    "    \"\"\"\n",
    "    # find classes under the folder\n",
    "    folder_path = os.path.expanduser(folder)\n",
    "    classes = os.listdir(folder_path) # class list\n",
    "    cls_to_idx = {name: i for i, name in enumerate(classes)} # {class name: index}\n",
    "        \n",
    "    # find files and make list of them\n",
    "    instances = {}\n",
    "    for cls in sorted(cls_to_idx.keys()):\n",
    "        cls_idx = cls_to_idx[cls]\n",
    "        cls_path = osp.join(folder_path, cls) # path to the class folder\n",
    "        files = os.listdir(cls_path) # list of images under the class\n",
    "        items = [(osp.join(cls_path, name), cls_idx) for name in files] # combine them to form complete paths\n",
    "        instances[cls_idx] = (items, len(items)) # (list of samples of the class, num of images in this class)\n",
    "        \n",
    "    return classes, cls_to_idx, instances\n",
    "\n",
    "# get the list of samples under the folder\n",
    "classes, cls_to_idx, instances = find_files(DATA_PATH)\n",
    "print(f'There are {len(classes)} classes and {sum([s[1] for s in instances.values()])} images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3534169",
   "metadata": {},
   "source": [
    "#### Split dataset\n",
    "若資料集本身沒有區分訓練集、驗證集或測試集，我們就必須手動分割出這些子集。\n",
    "\n",
    "這次作業採用「訓練集:測試集 = 8:2」的分割策略，對每個類別中的樣本都採用這個比例，這裡使用 ```sklearn``` 的 ```train_test_split``` 。\n",
    "\n",
    "請完成以下 ? 處以及被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c48ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "test_samples = []\n",
    "\n",
    "# iterate through all classes, split the samples and store them in the lists\n",
    "for cls_idx, cls_samples in instances.items():\n",
    "    train, test = train_test_split(?, test_size=?, random_state=SEED)  # split\n",
    "    train_samples += train\n",
    "    test_samples += test\n",
    "\n",
    "###############################################################################\n",
    "# TODO : use the sample lists to construct train dataset and test dataset     #\n",
    "# Hints:                                                                      #\n",
    "# train_dataset = DogDataset(?, ?, ?, ?)                                      #\n",
    "# test_dataset = DogDataset(?, ?, ?, ?)                                       #\n",
    "###############################################################################\n",
    "\n",
    "###############################################################################\n",
    "#                            END TODO                                         #\n",
    "###############################################################################\n",
    "\n",
    "print('Size of train dataset: %d, size of test dataset: %d' % (len(train_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c829f",
   "metadata": {},
   "source": [
    "### 1.4 Create dataloaders\n",
    "```DataLoader``` 負責將從 dataset 中得到的東西根據採樣策略 (```sampler```)、batch size 大小 (```batch_size```)、是否打亂資料順序 (```shuffle```)（訓練時通常會打亂），將樣本打包成一個 mini-batch ，並根據 ```num_workers``` 調整讀取資料的所需的資源。\n",
    "\n",
    "從 dataloader 中讀取資料的方式為像 python generator 或 list 一樣使用迴圈取出資料，可以在後面的訓練階段中看到。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337882b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = None\n",
    "test_loader = None\n",
    "###############################################################################\n",
    "# TODO : create dataloaders for train dataset and test dataset                #\n",
    "# Hints:                                                                      #\n",
    "# train_loader = DataLoader(?, ?, ?, ?)                                       #\n",
    "# test_loader = DogDataset(?, ?, ?, ?)                                        #\n",
    "###############################################################################\n",
    "\n",
    "###############################################################################\n",
    "#                            END TODO                                         #\n",
    "###############################################################################\n",
    "\n",
    "print(f'There are {len(train_loader)} training batches and {len(test_loader)} testing batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe672d",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "PyTorch 的模型（包括基本的 conv, batchnorm 層等等）大部分都是繼承 ```nn.Module```，並且都具備 \n",
    "+ ```__init__```: 定義內部結構，例如 conv, pool 等等。\n",
    "+ ```forward```: 定義前面的結構操作如何串聯，也就是這些結構的順序，是輸入的張量真正進行計算的 function 。\n",
    "\n",
    "用來建立模型的 API 有很多種，包括 ```nn.Module```、```nn.Sequential```、```nn.ModuleList```、```nn.ModuleDict``` 等等。\n",
    "\n",
    "這次作業要求以前兩種方法建立模型，分成 2.1 以及 2.2，並在這兩個部分裡完成下面所敘述的模型結構：\n",
    "1. A convolution layer with 64 11*11 filters, stride 4 and padding 2\n",
    "2. ReLU\n",
    "3. A Maxpooling layer with 3*3 kernel and stride 2\n",
    "4. A convolution layer with 128 5*5 filters and padding 2\n",
    "5. ReLU\n",
    "6. A Maxpooling layer with 3*3 kernel and stride 2\n",
    "7. A convolution layer with 256 3*3 filters and padding 1\n",
    "8. ReLU\n",
    "9. A convolution layer with 128 3*3 filters and padding 1\n",
    "10. ReLU\n",
    "11. A convolution layer with 128 3*3 filters and padding 1\n",
    "12. ReLU\n",
    "13. A Maxpooling layer with 3*3 kernel and stride 2\n",
    "14. flatten\n",
    "15. A fully-connected layer that outputs tensor to 1024\n",
    "16. ReLU\n",
    "17. A fully-connected layer that outputs tensor to 256\n",
    "18. ReLU\n",
    "19. A fully-connected layer that outputs tensor to 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0911c3",
   "metadata": {},
   "source": [
    "### 2.1 flatten function\n",
    "Flatten 作用是將 tensor 除了 batch 以外的其他維度全部攤平。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    ###############################################################################\n",
    "    # TODO : flatten the input tensor x with shape (B, C, H, W) to (B, C*H*W)     #\n",
    "    ###############################################################################    \n",
    "    \n",
    "    ###############################################################################\n",
    "    #                            END TODO                                         #\n",
    "    ###############################################################################\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34fbd6a",
   "metadata": {},
   "source": [
    "### 2.2 使用 nn.Module 建立模型\n",
    "如同一般定義 python class 的方法，在建構子中定義會用到的 layer ，並在 forward 中定義其之間的操作連結。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3081d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__() # this line must be done first\n",
    "        ###############################################################################\n",
    "        # TODO : Define the model described above by specifying the required layers   #\n",
    "        # Hints:                                                                      #\n",
    "        # self.conv1 = ?                                                              #\n",
    "        # self.relu = ?                                                               #\n",
    "        # self.maxpool1 = ?                                                           #\n",
    "        # self.conv2 = ?                                                              #\n",
    "        # ...                                                                         #\n",
    "        ###############################################################################\n",
    "        \n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                         #\n",
    "        ###############################################################################\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        ###############################################################################\n",
    "        # TODO : Implement the forward function, you should use the layers            #\n",
    "        #        defined in __init__ function and connect them                        #\n",
    "        # Hints:                                                                      #\n",
    "        # x = self.?(?)                                                               #\n",
    "        # x = self.?(?)                                                               #\n",
    "        # ...                                                                         #\n",
    "        ###############################################################################\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TODO                                         #\n",
    "        ###############################################################################\n",
    "        \n",
    "        return x\n",
    "\n",
    "x = torch.randn(4, 3, 224, 224)\n",
    "model = TestModel()\n",
    "make_dot(model(x), params=dict(model.named_parameters()))\n",
    "# 可以將畫出來的圖與助教提供的圖對比看看是否一樣或十分相似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0b33c",
   "metadata": {},
   "source": [
    "### 2.3 使用 nn.Sequential 建立模型\n",
    "```nn.Sequential``` 的不同之處在於可以直接從一系列的 layer 建立模型，不需定義 ```__init__``` 也不用定義 ```forward``` ，會自動依序用每一層進行 forward ，相對地，其成員皆需有 ```forward``` 可以呼叫。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9f4ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wrap the flatten function\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "model = None\n",
    "###############################################################################\n",
    "# TODO : Define the model described above using nn.Sequential                 #\n",
    "# Hints:                                                                      #\n",
    "# model = nn.Sequential(...)                                                  #\n",
    "###############################################################################\n",
    "\n",
    "###############################################################################\n",
    "#                            END TODO                                         #\n",
    "###############################################################################\n",
    "\n",
    "x = torch.randn(4, 3, 224, 224)\n",
    "make_dot(model(x), params=dict(model.named_parameters()))\n",
    "# 可以將畫出來的圖與助教提供的圖對比看看是否一樣或十分相似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2cc27",
   "metadata": {},
   "source": [
    "### 2.4 自行設計模型\n",
    "請使用上述任一種方式設計自己的模型(實體化後的模型名稱為 ```mymodel```)，並解釋自己的設計。最後的分類為 20 個類別。\n",
    "\n",
    "## **不可以直接呼叫```torchvision.models```中已經寫好的模型，但可以照著論文中的模型架構手刻出來**\n",
    "\n",
    "## **不可以使用預訓練過的模型權重作為初始狀態，也就是不能用預訓練的模型再 fine-tune**\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d94b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = None\n",
    "###############################################################################\n",
    "# TODO : Design your own model and instantiate as mymodel.                    #\n",
    "# Hint:                                                                       #\n",
    "# You can start from modifying the model above.                               #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                            END TODO                                         #\n",
    "###############################################################################\n",
    "x = torch.randn(4, 3, 224, 224)\n",
    "make_dot(mymodel(x), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bae4f0",
   "metadata": {},
   "source": [
    "#### 解釋寫在這裡\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a37fb",
   "metadata": {},
   "source": [
    "## 3 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e0efa",
   "metadata": {},
   "source": [
    "### 3.1 設定 loss function 以及 optimizer\n",
    "+ 對於分類問題，通常使用 cross entropy 就足夠\n",
    "+ Optimizer 常用的有 SGD, Adam 等等\n",
    "\n",
    "請完成以下 ? 處以及被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63336950",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = None\n",
    "optimizer = None\n",
    "###############################################################################\n",
    "# TODO : Setting up loss function (criterion) and optimizer                   #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                            END TODO                                         #\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b33ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這個 cell 不用填\n",
    "\n",
    "# helper functions\n",
    "def accuracy(outputs, targets):\n",
    "    \"\"\"Compute accuracy\"\"\"\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    pred = outputs.argmax(1)\n",
    "    correct = pred.eq(targets)\n",
    "    acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "    return acc\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"A Meter that records numbers and compute the average.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0.0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17783103",
   "metadata": {},
   "source": [
    "### 3.2 開始訓練\n",
    "流程：\n",
    "\n",
    "訓練階段，在一個 iteration 中，\n",
    "1. 取出 batch 中的資料\n",
    "2. 由模型預測分類結果 (forward)\n",
    "3. 計算 loss \n",
    "4. 清空梯度\n",
    "5. backward 計算梯度\n",
    "6. 更新模型參數\n",
    "\n",
    "重複以上動作直到所有 batch 迭代完成後，進入測試階段，使用測試集測試模型表現，計算準確度。\n",
    "\n",
    "到這裡是一個 epoch 的動作，重複直到設定的 epoch 數量後結束。\n",
    "\n",
    "以下會把每一個 epoch 的訓練和測試部份寫成兩個 function，請完成 ? 的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loader, criterion, optimizer):\n",
    "    \"\"\"This function trains for 1 epoch and returns the epoch loss and accuracy.\"\"\"\n",
    "    # recorders\n",
    "    loss_m = AverageMeter()\n",
    "    acc_m = AverageMeter()\n",
    "    \n",
    "    model.? # Set model to training mode\n",
    "    \n",
    "    for idx, (imgs, labels) in enumerate(loader): # load data\n",
    "        # put the data to correct device\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        # model forward\n",
    "        outputs = ?\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(?, ?)\n",
    "\n",
    "        # clear optimizer gradients\n",
    "        optimizer.?\n",
    "\n",
    "        # backward to calculate gradients\n",
    "        loss.?\n",
    "\n",
    "        # update model parameters\n",
    "        optimizer.?\n",
    "        \n",
    "        # accuracy\n",
    "        acc = accuracy(?, ?)\n",
    "        \n",
    "        # record loss and acc\n",
    "        loss_m.update(loss.item(), imgs.size(0))\n",
    "        acc_m.update(acc.item(), imgs.size(0))\n",
    "        \n",
    "        # logging\n",
    "        if (idx >= 0) and (idx % PRINT_FREQ == 0):\n",
    "            print(\"[{:3d}/{}] Train Loss {:.3f} Acc {:.3f}\".format(\n",
    "                idx, len(loader), loss_m.val, acc_m.val\n",
    "            ))\n",
    "        \n",
    "    return loss_m.avg, acc_m.avg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d615c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, criterion):\n",
    "    \"\"\"This function tests the model on the test set.\"\"\"\n",
    "    # recorders\n",
    "    loss_m = AverageMeter()\n",
    "    out_list, y_list = [], []\n",
    "    \n",
    "    model.? # set model to eval mode\n",
    "    \n",
    "    with torch.?: # no need to compute gradient when testing\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # model forward\n",
    "            outputs = ?\n",
    "            \n",
    "            # compute loss\n",
    "            loss = criterion(?, ?)\n",
    "            \n",
    "            y_list.append(labels)\n",
    "            out_list.append(outputs)\n",
    "            loss_m.update(loss.item())\n",
    "        \n",
    "        # concat all predictions and answers to compute accuracy\n",
    "        pred = torch.cat(out_list)\n",
    "        y = torch.cat(y_list)\n",
    "        acc = accuracy(?, ?)\n",
    "    \n",
    "    return loss_m.avg, acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd57a5f",
   "metadata": {},
   "source": [
    "#### Let's GOOOOOO\n",
    "\n",
    "請完成以下 ? 處，並執行這個 cell 以開始訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c1ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# move model to GPU if available\n",
    "if device == 'cuda':\n",
    "    mymodel.cuda()\n",
    "\n",
    "# for recording\n",
    "train_loss, test_loss = [], []\n",
    "train_acc, test_acc = [], []\n",
    "best_acc = (0, 0.0) # (epoch, acc)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"---------------- Epoch {} ----------------\".format(epoch+1))\n",
    "    \n",
    "    # training\n",
    "    loss, acc = train(?, ?, ?, ?, ?)\n",
    "    # saving epoch loss and acc for plotting\n",
    "    train_loss.append(loss)\n",
    "    train_acc.append(acc)\n",
    "    # logging\n",
    "    print('Epoch {:3d}/{} Train Loss {:.3f} Acc {:.3f}'.format(epoch+1, EPOCHS, loss, acc))\n",
    "    \n",
    "    # testing\n",
    "    print(\"---------------- Testing ----------------\")\n",
    "    loss, acc = test(?, ?, ?)\n",
    "    test_loss.append(loss)\n",
    "    test_acc.append(acc)        \n",
    "    # logging\n",
    "    print('Epoch {:3d}/{} Test Loss {:.3f} Acc {:.3f}'.format(epoch+1, EPOCHS, loss, acc))\n",
    "    \n",
    "    if acc > best_acc[1]:\n",
    "        best_acc = (epoch+1, acc)\n",
    "\n",
    "print('--' * 10)\n",
    "print('The Best accuracy is {:.3f} at epoch {}'.format(best_acc[1], best_acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492892fb",
   "metadata": {},
   "source": [
    "### 3.3 儲存模型\n",
    "PyTorch 提供 ```torch.save()``` API 可以儲存模型。\n",
    "\n",
    "PyTorch 建議使用 ```state_dict``` 來儲存模型(要存整個模型也可以)，```state_dict``` 包含模型的可學習參數(如 conv layers 的 weight 和 bias) 以及 registered buffer (如 batchnorm running mean) 。 由於 ```state_dict``` 屬於 python dictionaries ，所以有很大的使用彈性。\n",
    "\n",
    "這裡我們只儲存最後的模型狀態，你也可以在每一個 epoch 後儲存一個節點或儲存擁有最佳表現的模型。常用的附檔名為 ```.pt``` 或 ```.pth```。\n",
    "\n",
    "請完成以下 ? 處。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34aaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'mymodel.pth'\n",
    "torch.save(?, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8d5c6",
   "metadata": {},
   "source": [
    "### 3.4 繪製訓練過程的 loss 與 accuracy 變化\n",
    "在訓練過程中，我們透過 ```list``` 儲存每個 epoch 的 loss 和 accuracy，現在透過 ```matplotlib.pyplot``` 將這些數值畫成圖表，可以幫助我們分析訓練過程的變化。\n",
    "\n",
    "請完成以下 ? 處"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0d524",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting loss curves\n",
    "x = list(range(EPOCHS))\n",
    "plt.plot(x, ?, x, ?)\n",
    "plt.title('Training & Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Testing'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f465ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting acc curves\n",
    "x = list(range(EPOCHS))\n",
    "plt.plot(x, ?, x, ?)\n",
    "plt.title('Training & Testing Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Testing'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2336d",
   "metadata": {},
   "source": [
    "## 參考資料 & 教學\n",
    "\n",
    "### Transformations\n",
    "+ https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n",
    "+ https://pytorch.org/vision/stable/transforms.html 可以知道每種方法產生的效果\n",
    "+ https://chih-sheng-huang821.medium.com/03-pytorch-dataaug-a712a7a7f55e\n",
    "\n",
    "### Dataset\n",
    "+ https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
    "+ https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "\n",
    "### Dataloader\n",
    "+ https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders\n",
    "\n",
    "### Model\n",
    "#### Module\n",
    "+ https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "+ https://pytorch.org/docs/stable/nn.html (conv, batchnorm, pooling layer 的詳細用法可以在這裡找到)\n",
    "\n",
    "#### Custom Model\n",
    "+ https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html\n",
    "\n",
    "#### nn.Sequential\n",
    "+ https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
    "\n",
    "### Training\n",
    "#### Optimizer\n",
    "+ https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "#### Loss function\n",
    "+ https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "\n",
    "#### Saving model\n",
    "+ https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
